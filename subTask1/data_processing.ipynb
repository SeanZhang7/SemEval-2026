{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9505a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b494b86",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c5b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: train=2211, val=553\n",
      "Total rows: 2764\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# separate data into train and validation sets randomly (80% train, 20% val)\n",
    "\n",
    "FILE_PATH = \"../TRAIN_RELEASE_3SEP2025/train_subtask1.csv\"\n",
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# read\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# clean + sort \n",
    "df = df.dropna(subset=[\"user_id\", \"text_id\", \"text\", \"valence\", \"arousal\"]).copy()\n",
    "df = df.sort_values([\"user_id\", \"timestamp\", \"text_id\"]).reset_index(drop=True)\n",
    "\n",
    "# random split (80% train, 20% val)\n",
    "train_df, val_df = train_test_split(df, train_size=TRAIN_RATIO, random_state=SEED)\n",
    "\n",
    "# verify split\n",
    "print(f\"Rows: train={len(train_df)}, val={len(val_df)}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "#save\n",
    "train_df.to_pickle(\"data/train.pickle\")\n",
    "val_df.to_pickle(\"data/val.pickle\")\n",
    "\n",
    "\n",
    "print(\"Saved\")\n",
    "\n",
    "train=pd.read_pickle(\"data/train.pickle\")\n",
    "val=pd.read_pickle(\"data/val.pickle\")\n",
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "val.to_csv(\"data/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e464a15",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Generate LIWC Features\n",
    "Run the following commands in terminal or uncomment the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ca624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LIWC Features for train and validation\n",
    "# !python liwc_script.py --data subTask1/data/train.csv --column text --save ../subTask1/data/task1_LIWC_train\n",
    "# !python liwc_script.py --data subTask1/data/val.csv --column text --save ../subTask1/data/task1_LIWC_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985053f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Generate Valence and Arousal Similarity Features\n",
    "Run the following commands in terminal or uncomment the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb70f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Valence Arousal similarity Features\n",
    "# !cd extremism\n",
    "# !python item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/train.csv --text-column text --scale Valence --device cuda --output ../subTask1/data/task1_ValenceSim_train.pickle\n",
    "# !python item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/train.csv --text-column text --scale Arousal --device cuda --output ../subTask1/data/task1_ArousalSim_train.pickle\n",
    "# !python item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/val.csv --text-column text --scale Valence --device cuda --output ../subTask1/data/task1_ValenceSim_val.pickle\n",
    "# !python item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/val.csv --text-column text --scale Arousal --device cuda --output ../subTask1/data/task1_ArousalSim_val.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3ce138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211 2211 2211\n"
     ]
    }
   ],
   "source": [
    "train_A=pd.read_pickle('data/task1_ArousalSim_train.pickle')\n",
    "train_V=pd.read_pickle('data/task1_ValenceSim_train.pickle')\n",
    "val_A=pd.read_pickle('data/task1_ArousalSim_val.pickle')\n",
    "val_V=pd.read_pickle('data/task1_ValenceSim_val.pickle')\n",
    "train=pd.read_pickle('data/train.pickle')\n",
    "val=pd.read_pickle('data/val.pickle')\n",
    "print(len(train), len(train_A), len(train_V))\n",
    "\n",
    "train = pd.concat([train, train_A, train_V], axis=1)\n",
    "val = pd.concat([val, val_A, val_V], axis=1)\n",
    "train.to_pickle('data/train+sim.pickle')\n",
    "val.to_pickle('data/val+sim.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86563e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating embeddings for training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07862c056e1440e4b144c745b10c7dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for validation data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5d43183e6b46a5884e5e3a5d469670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2211, 9)\n",
      "Val data shape: (553, 9)\n",
      "Embedding column shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each text and save with original data\n",
    "# Load data\n",
    "train_df = pd.read_pickle(\"data/train.pickle\")\n",
    "val_df = pd.read_pickle(\"data/val.pickle\")\n",
    "\n",
    "# Setup device and model\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=DEVICE)\n",
    "\n",
    "# Generate embeddings for training data\n",
    "print(\"Generating embeddings for training data...\")\n",
    "train_embeddings = encoder.encode(\n",
    "    train_df[\"text\"].astype(str).tolist(),\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=False\n",
    ")\n",
    "train_df[\"embedding\"] = [emb.cpu().numpy() if hasattr(emb, 'cpu') else emb for emb in train_embeddings]\n",
    "\n",
    "# Generate embeddings for validation data\n",
    "print(\"Generating embeddings for validation data...\")\n",
    "val_embeddings = encoder.encode(\n",
    "    val_df[\"text\"].astype(str).tolist(),\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=False\n",
    ")\n",
    "val_df[\"embedding\"] = [emb.cpu().numpy() if hasattr(emb, 'cpu') else emb for emb in val_embeddings]\n",
    "\n",
    "# Save to pickle\n",
    "train_df.to_pickle(\"data/task1_embedding_train.pickle\")\n",
    "val_df.to_pickle(\"data/task1_embedding_val.pickle\")\n",
    "\n",
    "print(f\"Train data shape: {train_df.shape}\")\n",
    "print(f\"Val data shape: {val_df.shape}\")\n",
    "print(f\"Embedding column shape: {train_df['embedding'].iloc[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92c2ad",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae619ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"../TEST_RELEASE_5JAN2026/test_subtask1.csv\")\n",
    "test_df.to_pickle(\"data/test.pickle\")\n",
    "test_df.to_csv(\"data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92ea00",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Generate LIWC Features for Test Data\n",
    "Run the following command in terminal or uncomment the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LIWC Features for test data\n",
    "# !python ../liwc_script.py --data subTask1/data/test.csv --column text --save task1_LIWC_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe9188",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Generate Valence and Arousal Similarity Features for Test Data\n",
    "Run the following commands in terminal or uncomment the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Valence Arousal similarity Features for test data\n",
    "# !cd ../extremism\n",
    "# !python ../extremism/item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/test.csv --text-column text --scale Valence --device cuda\n",
    "# !python ../extremism/item-scoring/item_scoring.py --custom-dataset /u50/zhanh279/SemEval-2026/subTask1/data/test.csv --text-column text --scale Arousal --device cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7eeb3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737 1737 1737\n"
     ]
    }
   ],
   "source": [
    "test_A=pd.read_pickle('data/task1_ArousalSim_test.pickle')\n",
    "test_V=pd.read_pickle('data/task1_ValenceSim_test.pickle')\n",
    "test=pd.read_pickle('data/test.pickle')\n",
    "print(len(test), len(test_A), len(test_V))\n",
    "\n",
    "test = pd.concat([test, test_A, test_V], axis=1)\n",
    "test.to_pickle('data/test+sim.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c30140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating embeddings for test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8737726e3541d8b41e921fee2eff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1737, 8)\n",
      "Embedding column shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each text and save with original data\n",
    "# Load data\n",
    "test_df = pd.read_pickle(\"data/test.pickle\")\n",
    "\n",
    "# Setup device and model\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=DEVICE)\n",
    "\n",
    "# Generate embeddings for test data\n",
    "print(\"Generating embeddings for test data...\")\n",
    "test_embeddings = encoder.encode(\n",
    "    test_df[\"text\"].astype(str).tolist(),\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=False\n",
    ")\n",
    "test_df[\"embedding\"] = [emb.cpu().numpy() if hasattr(emb, 'cpu') else emb for emb in test_embeddings]\n",
    "# Save to pickle\n",
    "test_df.to_pickle(\"data/task1_embedding_test.pickle\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Embedding column shape: {test_df['embedding'].iloc[0].shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hongyi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
